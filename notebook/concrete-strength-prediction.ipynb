{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d99a062",
   "metadata": {
    "papermill": {
     "duration": 0.004223,
     "end_time": "2025-02-08T06:28:45.366195",
     "exception": false,
     "start_time": "2025-02-08T06:28:45.361972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Concrete Strength Prediction\n",
    "\n",
    "Predicting the strength of concrete's compressive strength using Random Forest and XGBoost and taking the weighted average of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984ca4a",
   "metadata": {
    "papermill": {
     "duration": 0.003125,
     "end_time": "2025-02-08T06:28:45.373213",
     "exception": false,
     "start_time": "2025-02-08T06:28:45.370088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Import the Libraries\n",
    "\n",
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5fd4e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T06:28:45.381315Z",
     "iopub.status.busy": "2025-02-08T06:28:45.380916Z",
     "iopub.status.idle": "2025-02-08T06:28:48.649151Z",
     "shell.execute_reply": "2025-02-08T06:28:48.647634Z"
    },
    "papermill": {
     "duration": 3.27469,
     "end_time": "2025-02-08T06:28:48.651254",
     "exception": false,
     "start_time": "2025-02-08T06:28:45.376564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries like scikit-learn and xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb4eb8",
   "metadata": {
    "papermill": {
     "duration": 0.003095,
     "end_time": "2025-02-08T06:28:48.658014",
     "exception": false,
     "start_time": "2025-02-08T06:28:48.654919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Prepare the Data\n",
    "\n",
    "Load the dataset from Kaggle and convert into numpy array, further splitting for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e83634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T06:28:48.665962Z",
     "iopub.status.busy": "2025-02-08T06:28:48.665431Z",
     "iopub.status.idle": "2025-02-08T06:28:48.726144Z",
     "shell.execute_reply": "2025-02-08T06:28:48.725061Z"
    },
    "papermill": {
     "duration": 0.067,
     "end_time": "2025-02-08T06:28:48.728287",
     "exception": false,
     "start_time": "2025-02-08T06:28:48.661287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Adnan\\AppData\\Local\\Temp\\ipykernel_4752\\3623444815.py:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data = pd.read_csv('D:\\PROJECTS\\Concrete-compressive-strength\\data\\concrete_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('D:\\PROJECTS\\Concrete-compressive-strength\\data\\concrete_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8f8cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T06:28:48.741477Z",
     "iopub.status.busy": "2025-02-08T06:28:48.740962Z",
     "iopub.status.idle": "2025-02-08T06:28:48.755670Z",
     "shell.execute_reply": "2025-02-08T06:28:48.754330Z"
    },
    "papermill": {
     "duration": 0.023859,
     "end_time": "2025-02-08T06:28:48.757964",
     "exception": false,
     "start_time": "2025-02-08T06:28:48.734105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "x_data = data.drop(columns = ['concrete_compressive_strength'])\n",
    "y_data = data['concrete_compressive_strength']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e049f6cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T06:28:48.772273Z",
     "iopub.status.busy": "2025-02-08T06:28:48.771703Z",
     "iopub.status.idle": "2025-02-08T06:28:48.777513Z",
     "shell.execute_reply": "2025-02-08T06:28:48.776374Z"
    },
    "papermill": {
     "duration": 0.01544,
     "end_time": "2025-02-08T06:28:48.779083",
     "exception": false,
     "start_time": "2025-02-08T06:28:48.763643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (824, 8)\n",
      "Length of the test data: 206\n"
     ]
    }
   ],
   "source": [
    "# Check the shape and length of the data\n",
    "shape = x_train.shape\n",
    "length = len(y_test)\n",
    "\n",
    "print(f\"Shape of the training data: {shape}\")\n",
    "print(f\"Length of the test data: {length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc81ba",
   "metadata": {
    "papermill": {
     "duration": 0.003479,
     "end_time": "2025-02-08T06:28:49.245447",
     "exception": false,
     "start_time": "2025-02-08T06:28:49.241968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. XGBoost\n",
    "\n",
    "* **XGBRegressor()**: XGBoost's implementation for regression using gradient boosting.\n",
    "\n",
    "* **n_estimators = 100**: Number of boosting rounds or trees to build.\n",
    "\n",
    "* **learning_rate = 0.1**: Controls the step size for weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7e4c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T06:28:49.254207Z",
     "iopub.status.busy": "2025-02-08T06:28:49.253791Z",
     "iopub.status.idle": "2025-02-08T06:28:49.395527Z",
     "shell.execute_reply": "2025-02-08T06:28:49.393075Z"
    },
    "papermill": {
     "duration": 0.147894,
     "end_time": "2025-02-08T06:28:49.397153",
     "exception": false,
     "start_time": "2025-02-08T06:28:49.249259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for XGBoost: 18.90292315579263\n",
      "R2 Score for XGBoost: 0.9326625197968461\n"
     ]
    }
   ],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(n_estimators = 10000, learning_rate = 0.1, max_depth = 5, random_state = 2)\n",
    "xgb_regressor.fit(x_train, y_train)\n",
    "\n",
    "y_predicted_xgb = xgb_regressor.predict(x_test)\n",
    "\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_predicted_xgb)\n",
    "r2_xgb = r2_score(y_test, y_predicted_xgb)\n",
    "print(f\"Mean Squared Error for XGBoost: {mse_xgb}\")\n",
    "print(f\"R2 Score for XGBoost: {r2_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482f497",
   "metadata": {},
   "source": [
    "# 4. Comprehensive Model Training Pipeline\n",
    "\n",
    "Training multiple machine learning models for concrete strength prediction and comparing their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53022b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries for comprehensive model training\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Additional ML algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Metrics for comprehensive evaluation\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train/test data from pipeline\n",
    "train_dir = 'D:/PROJECTS/Concrete-compressive-strength/data/3_train_test_data/train'\n",
    "test_dir = 'D:/PROJECTS/Concrete-compressive-strength/data/3_train_test_data/test'\n",
    "\n",
    "# Load training data\n",
    "X_train = pd.read_csv(f'{train_dir}/X_train.csv')\n",
    "y_train = pd.read_csv(f'{train_dir}/y_train.csv').values.ravel()\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv(f'{test_dir}/X_test.csv')\n",
    "y_test = pd.read_csv(f'{test_dir}/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n",
    "print(f\"\\nFeatures: {list(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive evaluation function\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function\n",
    "    \"\"\"\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Train_R2': r2_score(y_train, y_pred_train),\n",
    "        'Test_R2': r2_score(y_test, y_pred_test),\n",
    "        'Train_MSE': mean_squared_error(y_train, y_pred_train),\n",
    "        'Test_MSE': mean_squared_error(y_test, y_pred_test),\n",
    "        'Train_MAE': mean_absolute_error(y_train, y_pred_train),\n",
    "        'Test_MAE': mean_absolute_error(y_test, y_pred_test),\n",
    "        'Train_ExplainedVar': explained_variance_score(y_train, y_pred_train),\n",
    "        'Test_ExplainedVar': explained_variance_score(y_test, y_pred_test),\n",
    "        'RMSE_Train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        'RMSE_Test': np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    }\n",
    "    \n",
    "    return metrics, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models dictionary\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Polynomial Regression': None,  # Will be handled separately\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Extra Trees': ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "print(\"🚀 Starting Comprehensive Model Training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train each model\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Polynomial Regression':\n",
    "        continue  # Handle separately\n",
    "    \n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        metrics, trained_model = evaluate_model(model, X_train, X_test, y_train, y_test, model_name)\n",
    "        results.append(metrics)\n",
    "        trained_models[model_name] = trained_model\n",
    "        \n",
    "        print(f\"✅ {model_name} - Test R²: {metrics['Test_R2']:.4f}, Test RMSE: {metrics['RMSE_Test']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error training {model_name}: {str(e)}\")\n",
    "        \n",
    "print(\"\\n🔄 Training Polynomial Regression...\")\n",
    "\n",
    "# Handle Polynomial Regression separately\n",
    "try:\n",
    "    poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "    X_test_poly = poly_features.transform(X_test)\n",
    "    \n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    y_pred_train_poly = poly_model.predict(X_train_poly)\n",
    "    y_pred_test_poly = poly_model.predict(X_test_poly)\n",
    "    \n",
    "    poly_metrics = {\n",
    "        'Model': 'Polynomial Regression',\n",
    "        'Train_R2': r2_score(y_train, y_pred_train_poly),\n",
    "        'Test_R2': r2_score(y_test, y_pred_test_poly),\n",
    "        'Train_MSE': mean_squared_error(y_train, y_pred_train_poly),\n",
    "        'Test_MSE': mean_squared_error(y_test, y_pred_test_poly),\n",
    "        'Train_MAE': mean_absolute_error(y_train, y_pred_train_poly),\n",
    "        'Test_MAE': mean_absolute_error(y_test, y_pred_test_poly),\n",
    "        'Train_ExplainedVar': explained_variance_score(y_train, y_pred_train_poly),\n",
    "        'Test_ExplainedVar': explained_variance_score(y_test, y_pred_test_poly),\n",
    "        'RMSE_Train': np.sqrt(mean_squared_error(y_train, y_pred_train_poly)),\n",
    "        'RMSE_Test': np.sqrt(mean_squared_error(y_test, y_pred_test_poly))\n",
    "    }\n",
    "    \n",
    "    results.append(poly_metrics)\n",
    "    trained_models['Polynomial Regression'] = (poly_model, poly_features)\n",
    "    \n",
    "    print(f\"✅ Polynomial Regression - Test R²: {poly_metrics['Test_R2']:.4f}, Test RMSE: {poly_metrics['RMSE_Test']:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error training Polynomial Regression: {str(e)}\")\n",
    "\n",
    "print(f\"\\n🎉 Model training completed! {len(results)} models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde52dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by Test R² score (descending)\n",
    "results_df = results_df.sort_values('Test_R2', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"📊 MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<4} {'Model':<20} {'Test R²':<10} {'Test RMSE':<12} {'Test MAE':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"{idx+1:<4} {row['Model']:<20} {row['Test_R2']:<10.4f} {row['RMSE_Test']:<12.2f} {row['Test_MAE']:<10.2f}\")\n",
    "\n",
    "print(\"\\n🏆 Best performing model:\", results_df.iloc[0]['Model'])\n",
    "print(f\"Best Test R² Score: {results_df.iloc[0]['Test_R2']:.4f}\")\n",
    "\n",
    "# Display full results\n",
    "print(\"\\n📋 DETAILED RESULTS:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd33009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory and save comprehensive results\n",
    "results_dir = 'D:/PROJECTS/Concrete-compressive-strength/results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"💾 Saving results to: {results_dir}\")\n",
    "\n",
    "# 1. Save summary results\n",
    "summary_file = f\"{results_dir}/model_comparison_summary_{timestamp}.txt\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"CONCRETE STRENGTH PREDICTION - MODEL COMPARISON SUMMARY\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    f.write(f\"Training Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Dataset: Concrete Compressive Strength\\n\")\n",
    "    f.write(f\"Training Samples: {len(X_train)}\\n\")\n",
    "    f.write(f\"Test Samples: {len(X_test)}\\n\")\n",
    "    f.write(f\"Features: {X_train.shape[1]}\\n\\n\")\n",
    "    \n",
    "    f.write(\"MODEL RANKING (by Test R² Score):\\n\")\n",
    "    f.write(\"-\" * 50 + \"\\n\")\n",
    "    for idx, row in results_df.iterrows():\n",
    "        f.write(f\"{idx+1:2d}. {row['Model']:<20} R²: {row['Test_R2']:.4f} RMSE: {row['RMSE_Test']:.2f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nBEST MODEL: {results_df.iloc[0]['Model']}\\n\")\n",
    "    f.write(f\"Best R² Score: {results_df.iloc[0]['Test_R2']:.4f}\\n\")\n",
    "    f.write(f\"Best RMSE: {results_df.iloc[0]['RMSE_Test']:.2f}\\n\")\n",
    "\n",
    "# 2. Save detailed results\n",
    "detailed_file = f\"{results_dir}/detailed_model_results_{timestamp}.txt\"\n",
    "with open(detailed_file, 'w') as f:\n",
    "    f.write(\"CONCRETE STRENGTH PREDICTION - DETAILED MODEL RESULTS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        f.write(f\"MODEL: {row['Model']}\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"R² Score (Train): {row['Train_R2']:.6f}\\n\")\n",
    "        f.write(f\"R² Score (Test):  {row['Test_R2']:.6f}\\n\")\n",
    "        f.write(f\"MSE (Train):      {row['Train_MSE']:.6f}\\n\")\n",
    "        f.write(f\"MSE (Test):       {row['Test_MSE']:.6f}\\n\")\n",
    "        f.write(f\"MAE (Train):      {row['Train_MAE']:.6f}\\n\")\n",
    "        f.write(f\"MAE (Test):       {row['Test_MAE']:.6f}\\n\")\n",
    "        f.write(f\"RMSE (Train):     {row['RMSE_Train']:.6f}\\n\")\n",
    "        f.write(f\"RMSE (Test):      {row['RMSE_Test']:.6f}\\n\")\n",
    "        f.write(f\"Explained Var (Train): {row['Train_ExplainedVar']:.6f}\\n\")\n",
    "        f.write(f\"Explained Var (Test):  {row['Test_ExplainedVar']:.6f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# 3. Save CSV format for easy analysis\n",
    "csv_file = f\"{results_dir}/model_results_{timestamp}.csv\"\n",
    "results_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# 4. Save feature importance (for tree-based models)\n",
    "importance_file = f\"{results_dir}/feature_importance_{timestamp}.txt\"\n",
    "with open(importance_file, 'w') as f:\n",
    "    f.write(\"FEATURE IMPORTANCE ANALYSIS\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    \n",
    "    for model_name, model in trained_models.items():\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            f.write(f\"{model_name.upper()} FEATURE IMPORTANCE:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            \n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X_train.columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            for _, row in feature_importance.iterrows():\n",
    "                f.write(f\"{row['feature']:<25}: {row['importance']:.6f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "print(\"✅ Results saved successfully!\")\n",
    "print(f\"📁 Files created:\")\n",
    "print(f\"   • Summary: {summary_file}\")\n",
    "print(f\"   • Detailed: {detailed_file}\")\n",
    "print(f\"   • CSV: {csv_file}\")\n",
    "print(f\"   • Feature Importance: {importance_file}\")\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\n🎯 FINAL SUMMARY:\")\n",
    "print(f\"Best Model: {results_df.iloc[0]['Model']}\")\n",
    "print(f\"Test R² Score: {results_df.iloc[0]['Test_R2']:.4f}\")\n",
    "print(f\"Test RMSE: {results_df.iloc[0]['RMSE_Test']:.2f}\")\n",
    "print(f\"Test MAE: {results_df.iloc[0]['Test_MAE']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2330,
     "sourceId": 3928,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "vir-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.804535,
   "end_time": "2025-02-08T06:28:50.168070",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-08T06:28:42.363535",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
